# utils/model_loader.py

import os
import whisper
from dotenv import load_dotenv
from huggingface_hub import login
from transformers import AutoTokenizer
from speechbrain.pretrained import EncoderClassifier


def load_whisper_model(model_name="medium", save_dir="pretrained_models/whisper"):
    os.makedirs(save_dir, exist_ok=True)
    model_path = os.path.join(save_dir, f"{model_name}.pt")

    if os.path.exists(model_path):
        print(f"‚ö° Whisper: –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {model_path}")
        model = whisper.load_model(model_path)
    else:
        print(f"üîΩ Whisper: –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å '{model_name}' –≤ {save_dir}...")
        model = whisper.load_model(model_name, download_root=save_dir)
        print("‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

    return model


def load_bert_tokenizer(model_name="bert-base-multilingual-cased", save_dir="pretrained_models/bert"):
    print("üîê –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    load_dotenv()
    hf_token = os.getenv("HF_TOKEN")

    if not hf_token:
        raise ValueError("Hugging Face token not found in environment variables.")

    login(hf_token)
    print(f"üîΩ –°–∫–∞—á–∏–≤–∞–µ–º BERT —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤ {save_dir}...")
    tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=save_dir)
    print("‚úÖ BERT —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤.")
    return tokenizer


def load_speechbrain_encoder(save_dir="pretrained_models/speechbrain"):
    print(f"üîΩ –°–∫–∞—á–∏–≤–∞–µ–º SpeechBrain –º–æ–¥–µ–ª—å –≤ {save_dir}...")
    model = EncoderClassifier.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb",
        savedir=save_dir
    )
    print("‚úÖ SpeechBrain –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞.")
    return model
